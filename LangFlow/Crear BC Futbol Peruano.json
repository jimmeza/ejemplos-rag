{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "URLComponent",
            "id": "URLComponent-Y0wKH",
            "name": "page_results",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-Qye64",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-URLComponent-Y0wKH{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-Y0wKHœ,œnameœ:œpage_resultsœ,œoutput_typesœ:[œDataFrameœ]}-SplitText-Qye64{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-Qye64œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URLComponent-Y0wKH",
        "sourceHandle": "{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-Y0wKHœ,œnameœ:œpage_resultsœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "SplitText-Qye64",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-Qye64œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-Qye64",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "QdrantVectorStoreComponent-8cck1",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitText-Qye64{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-Qye64œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-QdrantVectorStoreComponent-8cck1{œfieldNameœ:œingest_dataœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-Qye64",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-Qye64œ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "QdrantVectorStoreComponent-8cck1",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OllamaEmbeddings",
            "id": "OllamaEmbeddings-YdJTm",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "QdrantVectorStoreComponent-8cck1",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OllamaEmbeddings-YdJTm{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-YdJTmœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-QdrantVectorStoreComponent-8cck1{œfieldNameœ:œembeddingœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OllamaEmbeddings-YdJTm",
        "sourceHandle": "{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-YdJTmœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "QdrantVectorStoreComponent-8cck1",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-hvWfL",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "QdrantVectorStoreComponent-8cck1",
            "inputTypes": [
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitText-hvWfL{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-hvWfLœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-QdrantVectorStoreComponent-8cck1{œfieldNameœ:œingest_dataœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SplitText-hvWfL",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-hvWfLœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "QdrantVectorStoreComponent-8cck1",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œQdrantVectorStoreComponent-8cck1œ,œinputTypesœ:[œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File",
            "id": "File-2MDv6",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-hvWfL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__File-2MDv6{œdataTypeœ:œFileœ,œidœ:œFile-2MDv6œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-SplitText-hvWfL{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-hvWfLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "File-2MDv6",
        "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-2MDv6œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SplitText-hvWfL",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-hvWfLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "URLComponent-Y0wKH",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Fetch content from one or more web pages, following links recursively.",
            "display_name": "URL",
            "documentation": "https://docs.langflow.org/components-data#url",
            "edited": false,
            "field_order": [
              "urls",
              "max_depth",
              "prevent_outside",
              "use_async",
              "format",
              "timeout",
              "headers",
              "filter_text_html",
              "continue_on_failure",
              "check_response_status",
              "autoset_encoding"
            ],
            "frozen": false,
            "icon": "layout-template",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Extracted Pages",
                "group_outputs": false,
                "method": "fetch_content",
                "name": "page_results",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Raw Content",
                "group_outputs": false,
                "method": "fetch_content_as_message",
                "name": "raw_results",
                "selected": null,
                "tool_mode": false,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "autoset_encoding": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Autoset Encoding",
                "dynamic": false,
                "info": "If enabled, automatically sets the encoding of the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "autoset_encoding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "check_response_status": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Check Response Status",
                "dynamic": false,
                "info": "If enabled, checks the response status of the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "check_response_status",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain_community.document_loaders import RecursiveUrlLoader\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.helpers.data import safe_convert\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output, SliderInput, TableInput\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.services.deps import get_settings_service\n\n# Constants\nDEFAULT_TIMEOUT = 30\nDEFAULT_MAX_DEPTH = 1\nDEFAULT_FORMAT = \"Text\"\nURL_REGEX = re.compile(\n    r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n    re.IGNORECASE,\n)\n\n\nclass URLComponent(Component):\n    \"\"\"A component that loads and parses content from web pages recursively.\n\n    This component allows fetching content from one or more URLs, with options to:\n    - Control crawl depth\n    - Prevent crawling outside the root domain\n    - Use async loading for better performance\n    - Extract either raw HTML or clean text\n    - Configure request headers and timeouts\n    \"\"\"\n\n    display_name = \"URL\"\n    description = \"Fetch content from one or more web pages, following links recursively.\"\n    documentation: str = \"https://docs.langflow.org/components-data#url\"\n    icon = \"layout-template\"\n    name = \"URLComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs to crawl recursively, by clicking the '+' button.\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n            input_types=[],\n        ),\n        SliderInput(\n            name=\"max_depth\",\n            display_name=\"Depth\",\n            info=(\n                \"Controls how many 'clicks' away from the initial page the crawler will go:\\n\"\n                \"- depth 1: only the initial page\\n\"\n                \"- depth 2: initial page + all pages linked directly from it\\n\"\n                \"- depth 3: initial page + direct links + links found on those direct link pages\\n\"\n                \"Note: This is about link traversal, not URL path depth.\"\n            ),\n            value=DEFAULT_MAX_DEPTH,\n            range_spec=RangeSpec(min=1, max=5, step=1),\n            required=False,\n            min_label=\" \",\n            max_label=\" \",\n            min_label_icon=\"None\",\n            max_label_icon=\"None\",\n            # slider_input=True\n        ),\n        BoolInput(\n            name=\"prevent_outside\",\n            display_name=\"Prevent Outside\",\n            info=(\n                \"If enabled, only crawls URLs within the same domain as the root URL. \"\n                \"This helps prevent the crawler from going to external websites.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_async\",\n            display_name=\"Use Async\",\n            info=(\n                \"If enabled, uses asynchronous loading which can be significantly faster \"\n                \"but might use more system resources.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.\",\n            options=[\"Text\", \"HTML\"],\n            value=DEFAULT_FORMAT,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=DEFAULT_TIMEOUT,\n            required=False,\n            advanced=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": get_settings_service().settings.user_agent}],\n            advanced=True,\n            input_types=[\"DataFrame\"],\n        ),\n        BoolInput(\n            name=\"filter_text_html\",\n            display_name=\"Filter Text/HTML\",\n            info=\"If enabled, filters out text/css content type from the results.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"continue_on_failure\",\n            display_name=\"Continue on Failure\",\n            info=\"If enabled, continues crawling even if some requests fail.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"check_response_status\",\n            display_name=\"Check Response Status\",\n            info=\"If enabled, checks the response status of the request.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autoset_encoding\",\n            display_name=\"Autoset Encoding\",\n            info=\"If enabled, automatically sets the encoding of the request.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Pages\", name=\"page_results\", method=\"fetch_content\"),\n        Output(display_name=\"Raw Content\", name=\"raw_results\", method=\"fetch_content_as_message\", tool_mode=False),\n    ]\n\n    @staticmethod\n    def validate_url(url: str) -> bool:\n        \"\"\"Validates if the given string matches URL pattern.\n\n        Args:\n            url: The URL string to validate\n\n        Returns:\n            bool: True if the URL is valid, False otherwise\n        \"\"\"\n        return bool(URL_REGEX.match(url))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensures the given string is a valid URL.\n\n        Args:\n            url: The URL string to validate and normalize\n\n        Returns:\n            str: The normalized URL\n\n        Raises:\n            ValueError: If the URL is invalid\n        \"\"\"\n        url = url.strip()\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n\n        return url\n\n    def _create_loader(self, url: str) -> RecursiveUrlLoader:\n        \"\"\"Creates a RecursiveUrlLoader instance with the configured settings.\n\n        Args:\n            url: The URL to load\n\n        Returns:\n            RecursiveUrlLoader: Configured loader instance\n        \"\"\"\n        headers_dict = {header[\"key\"]: header[\"value\"] for header in self.headers if header[\"value\"] is not None}\n        extractor = (lambda x: x) if self.format == \"HTML\" else (lambda x: BeautifulSoup(x, \"lxml\").get_text())\n\n        return RecursiveUrlLoader(\n            url=url,\n            max_depth=self.max_depth,\n            prevent_outside=self.prevent_outside,\n            use_async=self.use_async,\n            extractor=extractor,\n            timeout=self.timeout,\n            headers=headers_dict,\n            check_response_status=self.check_response_status,\n            continue_on_failure=self.continue_on_failure,\n            base_url=url,  # Add base_url to ensure consistent domain crawling\n            autoset_encoding=self.autoset_encoding,  # Enable automatic encoding detection\n            exclude_dirs=[],  # Allow customization of excluded directories\n            link_regex=None,  # Allow customization of link filtering\n        )\n\n    def fetch_url_contents(self) -> list[dict]:\n        \"\"\"Load documents from the configured URLs.\n\n        Returns:\n            List[Data]: List of Data objects containing the fetched content\n\n        Raises:\n            ValueError: If no valid URLs are provided or if there's an error loading documents\n        \"\"\"\n        try:\n            urls = list({self.ensure_url(url) for url in self.urls if url.strip()})\n            logger.debug(f\"URLs: {urls}\")\n            if not urls:\n                msg = \"No valid URLs provided.\"\n                raise ValueError(msg)\n\n            all_docs = []\n            for url in urls:\n                logger.debug(f\"Loading documents from {url}\")\n\n                try:\n                    loader = self._create_loader(url)\n                    docs = loader.load()\n\n                    if not docs:\n                        logger.warning(f\"No documents found for {url}\")\n                        continue\n\n                    logger.debug(f\"Found {len(docs)} documents from {url}\")\n                    all_docs.extend(docs)\n\n                except requests.exceptions.RequestException as e:\n                    logger.exception(f\"Error loading documents from {url}: {e}\")\n                    continue\n\n            if not all_docs:\n                msg = \"No documents were successfully loaded from any URL\"\n                raise ValueError(msg)\n\n            # data = [Data(text=doc.page_content, **doc.metadata) for doc in all_docs]\n            data = [\n                {\n                    \"text\": safe_convert(doc.page_content, clean_data=True),\n                    \"url\": doc.metadata.get(\"source\", \"\"),\n                    \"title\": doc.metadata.get(\"title\", \"\"),\n                    \"description\": doc.metadata.get(\"description\", \"\"),\n                    \"content_type\": doc.metadata.get(\"content_type\", \"\"),\n                    \"language\": doc.metadata.get(\"language\", \"\"),\n                }\n                for doc in all_docs\n            ]\n        except Exception as e:\n            error_msg = e.message if hasattr(e, \"message\") else e\n            msg = f\"Error loading documents: {error_msg!s}\"\n            logger.exception(msg)\n            raise ValueError(msg) from e\n        return data\n\n    def fetch_content(self) -> DataFrame:\n        \"\"\"Convert the documents to a DataFrame.\"\"\"\n        return DataFrame(data=self.fetch_url_contents())\n\n    def fetch_content_as_message(self) -> Message:\n        \"\"\"Convert the documents to a Message.\"\"\"\n        url_contents = self.fetch_url_contents()\n        return Message(text=\"\\n\\n\".join([x[\"text\"] for x in url_contents]), data={\"data\": url_contents})\n"
              },
              "continue_on_failure": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Continue on Failure",
                "dynamic": false,
                "info": "If enabled, continues crawling even if some requests fail.",
                "list": false,
                "list_add_label": "Add More",
                "name": "continue_on_failure",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "filter_text_html": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Filter Text/HTML",
                "dynamic": false,
                "info": "If enabled, filters out text/css content type from the results.",
                "list": false,
                "list_add_label": "Add More",
                "name": "filter_text_html",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "format": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Output Format",
                "dynamic": false,
                "external_options": {},
                "info": "Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.",
                "name": "format",
                "options": [
                  "Text",
                  "HTML"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Text"
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "DataFrame"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Header name",
                      "disable_edit": false,
                      "display_name": "Header",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Header value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true,
                      "type": "str"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "User-Agent",
                    "value": "langflow"
                  }
                ]
              },
              "max_depth": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Depth",
                "dynamic": false,
                "info": "Controls how many 'clicks' away from the initial page the crawler will go:\n- depth 1: only the initial page\n- depth 2: initial page + all pages linked directly from it\n- depth 3: initial page + direct links + links found on those direct link pages\nNote: This is about link traversal, not URL path depth.",
                "max_label": " ",
                "max_label_icon": "None",
                "min_label": " ",
                "min_label_icon": "None",
                "name": "max_depth",
                "placeholder": "",
                "range_spec": {
                  "max": 5,
                  "min": 1,
                  "step": 1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "prevent_outside": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Prevent Outside",
                "dynamic": false,
                "info": "If enabled, only crawls URLs within the same domain as the root URL. This helps prevent the crawler from going to external websites.",
                "list": false,
                "list_add_label": "Add More",
                "name": "prevent_outside",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the request in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 30
              },
              "urls": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URLs",
                "dynamic": false,
                "info": "Enter one or more URLs to crawl recursively, by clicking the '+' button.",
                "input_types": [],
                "list": true,
                "list_add_label": "Add URL",
                "load_from_db": false,
                "name": "urls",
                "placeholder": "Enter a URL...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "https://es.wikipedia.org/wiki/F%C3%BAtbol_en_el_Per%C3%BA",
                  "https://es.wikipedia.org/wiki/Copas_nacionales_del_f%C3%BAtbol_peruano"
                ]
              },
              "use_async": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Async",
                "dynamic": false,
                "info": "If enabled, uses asynchronous loading which can be significantly faster but might use more system resources.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_async",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "page_results",
          "showNode": true,
          "type": "URLComponent"
        },
        "dragging": false,
        "id": "URLComponent-Y0wKH",
        "measured": {
          "height": 337,
          "width": 320
        },
        "position": {
          "x": 736.9039404826095,
          "y": -42.86008156107846
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitText-Qye64",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "https://docs.langflow.org/components-processing#split-text",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator",
              "text_key",
              "keep_separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "method": "split_text",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"
              },
              "data_inputs": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "external_options": {},
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitText"
        },
        "dragging": false,
        "id": "SplitText-Qye64",
        "measured": {
          "height": 411,
          "width": 320
        },
        "position": {
          "x": 1215.2107180266667,
          "y": -59.631527091147575
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "QdrantVectorStoreComponent-8cck1",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "qdrant",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Qdrant Vector Store with search capabilities",
            "display_name": "Qdrant",
            "documentation": "",
            "edited": false,
            "field_order": [
              "collection_name",
              "host",
              "port",
              "grpc_port",
              "api_key",
              "prefix",
              "timeout",
              "path",
              "url",
              "distance_func",
              "content_payload_key",
              "metadata_payload_key",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "Qdrant",
            "key": "QdrantVectorStoreComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "group_outputs": false,
                "method": "search_documents",
                "name": "search_results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "group_outputs": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 5.97035286583837e-8,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Qdrant API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain.embeddings.base import Embeddings\nfrom langchain_community.vectorstores import Qdrant\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema.data import Data\n\n\nclass QdrantVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Qdrant\"\n    description = \"Qdrant Vector Store with search capabilities\"\n    icon = \"Qdrant\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"host\", display_name=\"Host\", value=\"localhost\", advanced=True),\n        IntInput(name=\"port\", display_name=\"Port\", value=6333, advanced=True),\n        IntInput(name=\"grpc_port\", display_name=\"gRPC Port\", value=6334, advanced=True),\n        SecretStrInput(name=\"api_key\", display_name=\"Qdrant API Key\", advanced=True),\n        StrInput(name=\"prefix\", display_name=\"Prefix\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        StrInput(name=\"path\", display_name=\"Path\", advanced=True),\n        StrInput(name=\"url\", display_name=\"URL\", advanced=True),\n        DropdownInput(\n            name=\"distance_func\",\n            display_name=\"Distance Function\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        StrInput(name=\"content_payload_key\", display_name=\"Content Payload Key\", value=\"page_content\", advanced=True),\n        StrInput(name=\"metadata_payload_key\", display_name=\"Metadata Payload Key\", value=\"metadata\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Qdrant:\n        qdrant_kwargs = {\n            \"collection_name\": self.collection_name,\n            \"content_payload_key\": self.content_payload_key,\n            \"metadata_payload_key\": self.metadata_payload_key,\n        }\n\n        server_kwargs = {\n            \"host\": self.host or None,\n            \"port\": int(self.port),  # Ensure port is an integer\n            \"grpc_port\": int(self.grpc_port),  # Ensure grpc_port is an integer\n            \"api_key\": self.api_key,\n            \"prefix\": self.prefix,\n            # Ensure timeout is an integer\n            \"timeout\": int(self.timeout) if self.timeout else None,\n            \"path\": self.path or None,\n            \"url\": self.url or None,\n        }\n\n        server_kwargs = {k: v for k, v in server_kwargs.items() if v is not None}\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if not isinstance(self.embedding, Embeddings):\n            msg = \"Invalid embedding object\"\n            raise TypeError(msg)\n\n        if documents:\n            qdrant = Qdrant.from_documents(documents, embedding=self.embedding, **qdrant_kwargs, **server_kwargs)\n        else:\n            from qdrant_client import QdrantClient\n\n            client = QdrantClient(**server_kwargs)\n            qdrant = Qdrant(embeddings=self.embedding, client=client, **qdrant_kwargs)\n\n        return qdrant\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "LANGFLOW-Futbol-Peruano"
              },
              "content_payload_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Content Payload Key",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "content_payload_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "page_content"
              },
              "distance_func": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Distance Function",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "distance_func",
                "options": [
                  "Cosine",
                  "Euclidean",
                  "Dot Product"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Cosine"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "grpc_port": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "gRPC Port",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "grpc_port",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 6334
              },
              "host": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Host",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "host",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "metadata_payload_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Payload Key",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_payload_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "metadata"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "path": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Path",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "port": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Port",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "port",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 6333
              },
              "prefix": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Prefix",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "prefix",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "url": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:6333"
              }
            },
            "tool_mode": false
          },
          "selected_output": "search_results",
          "showNode": true,
          "type": "QdrantVectorStoreComponent"
        },
        "dragging": false,
        "id": "QdrantVectorStoreComponent-8cck1",
        "measured": {
          "height": 537,
          "width": 320
        },
        "position": {
          "x": 2048.479164098122,
          "y": 77.63132297568511
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OllamaEmbeddings-YdJTm",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "ollama",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Ollama models.",
            "display_name": "Ollama Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
            "edited": false,
            "field_order": [
              "model_name",
              "base_url"
            ],
            "frozen": false,
            "icon": "Ollama",
            "key": "OllamaEmbeddings",
            "last_updated": "2025-10-03T22:39:49.969Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "options": null,
                "required_inputs": null,
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.05200327751882152,
            "template": {
              "_type": "Component",
              "base_url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Ollama Base URL",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "base_url",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import OllamaEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.ollama_constants import OLLAMA_EMBEDDING_MODELS, URL_LIST\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import DropdownInput, MessageTextInput, Output\n\nHTTP_STATUS_OK = 200\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"OllamaEmbeddings\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Ollama Model\",\n            value=\"\",\n            options=[],\n            real_time_refresh=True,\n            refresh_button=True,\n            combobox=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=self.model_name, base_url=self.base_url)\n        except Exception as e:\n            msg = (\n                \"Unable to connect to the Ollama API. \",\n                \"Please verify the base URL, ensure the relevant Ollama model is pulled, and try again.\",\n            )\n            raise ValueError(msg) from e\n        return output\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\"} and not await self.is_valid_ollama_url(field_value):\n            # Check if any URL in the list is valid\n            valid_url = \"\"\n            for url in URL_LIST:\n                if await self.is_valid_ollama_url(url):\n                    valid_url = url\n                    break\n            build_config[\"base_url\"][\"value\"] = valid_url\n        if field_name in {\"model_name\", \"base_url\", \"tool_model_enabled\"}:\n            if await self.is_valid_ollama_url(self.base_url):\n                build_config[\"model_name\"][\"options\"] = await self.get_model(self.base_url)\n            elif await self.is_valid_ollama_url(build_config[\"base_url\"].get(\"value\", \"\")):\n                build_config[\"model_name\"][\"options\"] = await self.get_model(build_config[\"base_url\"].get(\"value\", \"\"))\n            else:\n                build_config[\"model_name\"][\"options\"] = []\n\n        return build_config\n\n    async def get_model(self, base_url_value: str) -> list[str]:\n        \"\"\"Get the model names from Ollama.\"\"\"\n        model_ids = []\n        try:\n            url = urljoin(base_url_value, \"/api/tags\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n            model_ids = [model[\"name\"] for model in data.get(\"models\", [])]\n            # this to ensure that not embedding models are included.\n            # not even the base models since models can have 1b 2b etc\n            # handles cases when embeddings models have tags like :latest - etc.\n            model_ids = [\n                model\n                for model in model_ids\n                if any(model.startswith(f\"{embedding_model}\") for embedding_model in OLLAMA_EMBEDDING_MODELS)\n            ]\n\n        except (ImportError, ValueError, httpx.RequestError) as e:\n            msg = \"Could not get model names from Ollama.\"\n            raise ValueError(msg) from e\n\n        return model_ids\n\n    async def is_valid_ollama_url(self, url: str) -> bool:\n        try:\n            async with httpx.AsyncClient() as client:\n                return (await client.get(f\"{url}/api/tags\")).status_code == HTTP_STATUS_OK\n        except httpx.RequestError:\n            return False\n"
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Ollama Model",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "all-minilm:latest",
                  "nomic-embed-text:latest"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "all-minilm:latest"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OllamaEmbeddings"
        },
        "dragging": false,
        "id": "OllamaEmbeddings-YdJTm",
        "measured": {
          "height": 285,
          "width": 320
        },
        "position": {
          "x": 1687.6151358745267,
          "y": 750.3520566709061
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "File-2MDv6",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Loads content from one or more files.",
            "display_name": "File",
            "documentation": "https://docs.langflow.org/components-data#file",
            "edited": false,
            "field_order": [
              "path",
              "file_path",
              "separator",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "advanced_mode",
              "pipeline",
              "ocr_engine",
              "md_image_placeholder",
              "md_page_break_placeholder",
              "doc_key",
              "use_multithreading",
              "concurrency_multithreading",
              "markdown"
            ],
            "frozen": false,
            "icon": "file-text",
            "last_updated": "2025-12-02T23:15:17.186Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Raw Content",
                "group_outputs": false,
                "hidden": null,
                "method": "load_files_message",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "hidden": null,
                "method": "load_files_path",
                "name": "path",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "advanced_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Advanced Parser",
                "dynamic": false,
                "info": "Enable advanced document processing and export with Docling for PDFs, images, and office documents. Available only for single file processing.Note that advanced document processing can consume significant resources.",
                "list": false,
                "list_add_label": "Add More",
                "name": "advanced_mode",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Enhanced file component with Docling support and process isolation.\n\nNotes:\n-----\n- ALL Docling parsing/export runs in a separate OS process to prevent memory\n  growth and native library state from impacting the main Langflow process.\n- Standard text/structured parsing continues to use existing BaseFileComponent\n  utilities (and optional threading via `parallel_load_data`).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport subprocess\nimport sys\nimport textwrap\nfrom copy import deepcopy\nfrom typing import TYPE_CHECKING, Any\n\nfrom langflow.base.data.base_file import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import (\n    BoolInput,\n    DropdownInput,\n    FileInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    StrInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\n\nif TYPE_CHECKING:\n    from langflow.schema import DataFrame\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"File component with optional Docling processing (isolated in a subprocess).\"\"\"\n\n    display_name = \"File\"\n    description = \"Loads content from one or more files.\"\n    documentation: str = \"https://docs.langflow.org/components-data#file\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    # Docling-supported/compatible extensions; TEXT_FILE_TYPES are supported by the base loader.\n    VALID_EXTENSIONS = [\n        *TEXT_FILE_TYPES,\n        \"adoc\",\n        \"asciidoc\",\n        \"asc\",\n        \"bmp\",\n        \"dotx\",\n        \"dotm\",\n        \"docm\",\n        \"jpeg\",\n        \"png\",\n        \"potx\",\n        \"ppsx\",\n        \"pptm\",\n        \"potm\",\n        \"ppsm\",\n        \"pptx\",\n        \"tiff\",\n        \"xls\",\n        \"xlsx\",\n        \"xhtml\",\n        \"webp\",\n    ]\n\n    # Fixed export settings used when markdown export is requested.\n    EXPORT_FORMAT = \"Markdown\"\n    IMAGE_MODE = \"placeholder\"\n\n    # ---- Inputs / Outputs (kept as close to original as possible) -------------------\n    _base_inputs = deepcopy(BaseFileComponent._base_inputs)\n    for input_item in _base_inputs:\n        if isinstance(input_item, FileInput) and input_item.name == \"path\":\n            input_item.real_time_refresh = True\n            break\n\n    inputs = [\n        *_base_inputs,\n        BoolInput(\n            name=\"advanced_mode\",\n            display_name=\"Advanced Parser\",\n            value=False,\n            real_time_refresh=True,\n            info=(\n                \"Enable advanced document processing and export with Docling for PDFs, images, and office documents. \"\n                \"Available only for single file processing.\"\n                \"Note that advanced document processing can consume significant resources.\"\n            ),\n            show=False,\n        ),\n        DropdownInput(\n            name=\"pipeline\",\n            display_name=\"Pipeline\",\n            info=\"Docling pipeline to use\",\n            options=[\"standard\", \"vlm\"],\n            value=\"standard\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"ocr_engine\",\n            display_name=\"OCR Engine\",\n            info=\"OCR engine to use. Only available when pipeline is set to 'standard'.\",\n            options=[\"None\", \"easyocr\"],\n            value=\"easyocr\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"md_image_placeholder\",\n            display_name=\"Image placeholder\",\n            info=\"Specify the image placeholder for markdown exports.\",\n            value=\"<!-- image -->\",\n            advanced=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"md_page_break_placeholder\",\n            display_name=\"Page break placeholder\",\n            info=\"Add this placeholder between pages in the markdown output.\",\n            value=\"\",\n            advanced=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"doc_key\",\n            display_name=\"Doc Key\",\n            info=\"The key to use for the DoclingDocument column.\",\n            value=\"doc\",\n            advanced=True,\n            show=False,\n        ),\n        # Deprecated input retained for backward-compatibility.\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n        BoolInput(\n            name=\"markdown\",\n            display_name=\"Markdown Export\",\n            info=\"Export processed documents to Markdown format. Only available when advanced mode is enabled.\",\n            value=False,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n    ]\n\n    # ------------------------------ UI helpers --------------------------------------\n\n    def _path_value(self, template: dict) -> list[str]:\n        \"\"\"Return the list of currently selected file paths from the template.\"\"\"\n        return template.get(\"path\", {}).get(\"file_path\", [])\n\n    def update_build_config(\n        self,\n        build_config: dict[str, Any],\n        field_value: Any,\n        field_name: str | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Show/hide Advanced Parser and related fields based on selection context.\"\"\"\n        if field_name == \"path\":\n            paths = self._path_value(build_config)\n            file_path = paths[0] if paths else \"\"\n            file_count = len(field_value) if field_value else 0\n\n            # Advanced mode only for single (non-tabular) file\n            allow_advanced = file_count == 1 and not file_path.endswith((\".csv\", \".xlsx\", \".parquet\"))\n            build_config[\"advanced_mode\"][\"show\"] = allow_advanced\n            if not allow_advanced:\n                build_config[\"advanced_mode\"][\"value\"] = False\n                for f in (\"pipeline\", \"ocr_engine\", \"doc_key\", \"md_image_placeholder\", \"md_page_break_placeholder\"):\n                    if f in build_config:\n                        build_config[f][\"show\"] = False\n\n        # Docling Processing\n        elif field_name == \"advanced_mode\":\n            for f in (\"pipeline\", \"ocr_engine\", \"doc_key\", \"md_image_placeholder\", \"md_page_break_placeholder\"):\n                if f in build_config:\n                    build_config[f][\"show\"] = bool(field_value)\n\n        elif field_name == \"pipeline\":\n            if field_value == \"standard\":\n                build_config[\"ocr_engine\"][\"show\"] = True\n                build_config[\"ocr_engine\"][\"value\"] = \"easyocr\"\n            else:\n                build_config[\"ocr_engine\"][\"show\"] = False\n                build_config[\"ocr_engine\"][\"value\"] = \"None\"\n\n        return build_config\n\n    def update_outputs(self, frontend_node: dict[str, Any], field_name: str, field_value: Any) -> dict[str, Any]:  # noqa: ARG002\n        \"\"\"Dynamically show outputs based on file count/type and advanced mode.\"\"\"\n        if field_name not in [\"path\", \"advanced_mode\", \"pipeline\"]:\n            return frontend_node\n\n        template = frontend_node.get(\"template\", {})\n        paths = self._path_value(template)\n        if not paths:\n            return frontend_node\n\n        frontend_node[\"outputs\"] = []\n        if len(paths) == 1:\n            file_path = paths[0] if field_name == \"path\" else frontend_node[\"template\"][\"path\"][\"file_path\"][0]\n            if file_path.endswith((\".csv\", \".xlsx\", \".parquet\")):\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Content\", name=\"dataframe\", method=\"load_files_structured\"),\n                )\n            elif file_path.endswith(\".json\"):\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Content\", name=\"json\", method=\"load_files_json\"),\n                )\n\n            advanced_mode = frontend_node.get(\"template\", {}).get(\"advanced_mode\", {}).get(\"value\", False)\n            if advanced_mode:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Output\", name=\"advanced_dataframe\", method=\"load_files_dataframe\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Markdown\", name=\"advanced_markdown\", method=\"load_files_markdown\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n            else:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n        else:\n            # Multiple files => DataFrame output; advanced parser disabled\n            frontend_node[\"outputs\"].append(Output(display_name=\"Files\", name=\"dataframe\", method=\"load_files\"))\n\n        return frontend_node\n\n    # ------------------------------ Core processing ----------------------------------\n\n    def _is_docling_compatible(self, file_path: str) -> bool:\n        \"\"\"Lightweight extension gate for Docling-compatible types.\"\"\"\n        docling_exts = (\n            \".adoc\",\n            \".asciidoc\",\n            \".asc\",\n            \".bmp\",\n            \".csv\",\n            \".dotx\",\n            \".dotm\",\n            \".docm\",\n            \".docx\",\n            \".htm\",\n            \".html\",\n            \".jpeg\",\n            \".json\",\n            \".md\",\n            \".pdf\",\n            \".png\",\n            \".potx\",\n            \".ppsx\",\n            \".pptm\",\n            \".potm\",\n            \".ppsm\",\n            \".pptx\",\n            \".tiff\",\n            \".txt\",\n            \".xls\",\n            \".xlsx\",\n            \".xhtml\",\n            \".xml\",\n            \".webp\",\n        )\n        return file_path.lower().endswith(docling_exts)\n\n    def _process_docling_in_subprocess(self, file_path: str) -> Data | None:\n        \"\"\"Run Docling in a separate OS process and map the result to a Data object.\n\n        We avoid multiprocessing pickling by launching `python -c \"<script>\"` and\n        passing JSON config via stdin. The child prints a JSON result to stdout.\n        \"\"\"\n        if not file_path:\n            return None\n\n        args: dict[str, Any] = {\n            \"file_path\": file_path,\n            \"markdown\": bool(self.markdown),\n            \"image_mode\": str(self.IMAGE_MODE),\n            \"md_image_placeholder\": str(self.md_image_placeholder),\n            \"md_page_break_placeholder\": str(self.md_page_break_placeholder),\n            \"pipeline\": str(self.pipeline),\n            \"ocr_engine\": (\n                self.ocr_engine if self.ocr_engine and self.ocr_engine != \"None\" and self.pipeline != \"vlm\" else None\n            ),\n        }\n\n        self.log(f\"Starting Docling subprocess for file: {file_path}\")\n        self.log(args)\n\n        # Child script for isolating the docling processing\n        child_script = textwrap.dedent(\n            r\"\"\"\n            import json, sys\n\n            def try_imports():\n                # Strategy 1: latest layout\n                try:\n                    from docling.datamodel.base_models import ConversionStatus, InputFormat  # type: ignore\n                    from docling.document_converter import DocumentConverter  # type: ignore\n                    from docling_core.types.doc import ImageRefMode  # type: ignore\n                    return ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, \"latest\"\n                except Exception:\n                    pass\n                # Strategy 2: alternative layout\n                try:\n                    from docling.document_converter import DocumentConverter  # type: ignore\n                    try:\n                        from docling_core.types import ConversionStatus, InputFormat  # type: ignore\n                    except Exception:\n                        try:\n                            from docling.datamodel import ConversionStatus, InputFormat  # type: ignore\n                        except Exception:\n                            class ConversionStatus: SUCCESS = \"success\"\n                            class InputFormat:\n                                PDF=\"pdf\"; IMAGE=\"image\"\n                    try:\n                        from docling_core.types.doc import ImageRefMode  # type: ignore\n                    except Exception:\n                        class ImageRefMode:\n                            PLACEHOLDER=\"placeholder\"; EMBEDDED=\"embedded\"\n                    return ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, \"alternative\"\n                except Exception:\n                    pass\n                # Strategy 3: basic converter only\n                try:\n                    from docling.document_converter import DocumentConverter  # type: ignore\n                    class ConversionStatus: SUCCESS = \"success\"\n                    class InputFormat:\n                        PDF=\"pdf\"; IMAGE=\"image\"\n                    class ImageRefMode:\n                        PLACEHOLDER=\"placeholder\"; EMBEDDED=\"embedded\"\n                    return ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, \"basic\"\n                except Exception as e:\n                    raise ImportError(f\"Docling imports failed: {e}\") from e\n\n            def create_converter(strategy, input_format, DocumentConverter, pipeline, ocr_engine):\n                # --- Standard PDF/IMAGE pipeline (your existing behavior), with optional OCR ---\n                if pipeline == \"standard\":\n                    try:\n                        from docling.datamodel.pipeline_options import PdfPipelineOptions  # type: ignore\n                        from docling.document_converter import PdfFormatOption  # type: ignore\n\n                        pipe = PdfPipelineOptions()\n                        pipe.do_ocr = False\n\n                        if ocr_engine:\n                            try:\n                                from docling.models.factories import get_ocr_factory  # type: ignore\n                                pipe.do_ocr = True\n                                fac = get_ocr_factory(allow_external_plugins=False)\n                                pipe.ocr_options = fac.create_options(kind=ocr_engine)\n                            except Exception:\n                                # If OCR setup fails, disable it\n                                pipe.do_ocr = False\n\n                        fmt = {}\n                        if hasattr(input_format, \"PDF\"):\n                            fmt[getattr(input_format, \"PDF\")] = PdfFormatOption(pipeline_options=pipe)\n                        if hasattr(input_format, \"IMAGE\"):\n                            fmt[getattr(input_format, \"IMAGE\")] = PdfFormatOption(pipeline_options=pipe)\n\n                        return DocumentConverter(format_options=fmt)\n                    except Exception:\n                        return DocumentConverter()\n\n                # --- Vision-Language Model (VLM) pipeline ---\n                if pipeline == \"vlm\":\n                    try:\n                        from docling.pipeline.vlm_pipeline import VlmPipeline\n                        from docling.document_converter import PdfFormatOption  # type: ignore\n\n                        vl_pipe = VlmPipelineOptions()\n\n                        # VLM paths generally don't need OCR; keep OCR off by default here.\n                        fmt = {}\n                        if hasattr(input_format, \"PDF\"):\n                            fmt[getattr(input_format, \"PDF\")] = PdfFormatOption(pipeline_cls=VlmPipeline)\n                        if hasattr(input_format, \"IMAGE\"):\n                            fmt[getattr(input_format, \"IMAGE\")] = PdfFormatOption(pipeline_cls=VlmPipeline)\n\n                        return DocumentConverter(format_options=fmt)\n                    except Exception:\n                        return DocumentConverter()\n\n                # --- Fallback: default converter with no special options ---\n                return DocumentConverter()\n\n            def export_markdown(document, ImageRefMode, image_mode, img_ph, pg_ph):\n                try:\n                    mode = getattr(ImageRefMode, image_mode.upper(), image_mode)\n                    return document.export_to_markdown(\n                        image_mode=mode,\n                        image_placeholder=img_ph,\n                        page_break_placeholder=pg_ph,\n                    )\n                except Exception:\n                    try:\n                        return document.export_to_text()\n                    except Exception:\n                        return str(document)\n\n            def to_rows(doc_dict):\n                rows = []\n                for t in doc_dict.get(\"texts\", []):\n                    prov = t.get(\"prov\") or []\n                    page_no = None\n                    if prov and isinstance(prov, list) and isinstance(prov[0], dict):\n                        page_no = prov[0].get(\"page_no\")\n                    rows.append({\n                        \"page_no\": page_no,\n                        \"label\": t.get(\"label\"),\n                        \"text\": t.get(\"text\"),\n                        \"level\": t.get(\"level\"),\n                    })\n                return rows\n\n            def main():\n                cfg = json.loads(sys.stdin.read())\n                file_path = cfg[\"file_path\"]\n                markdown = cfg[\"markdown\"]\n                image_mode = cfg[\"image_mode\"]\n                img_ph = cfg[\"md_image_placeholder\"]\n                pg_ph = cfg[\"md_page_break_placeholder\"]\n                pipeline = cfg[\"pipeline\"]\n                ocr_engine = cfg.get(\"ocr_engine\")\n                meta = {\"file_path\": file_path}\n\n                try:\n                    ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, strategy = try_imports()\n                    converter = create_converter(strategy, InputFormat, DocumentConverter, pipeline, ocr_engine)\n                    try:\n                        res = converter.convert(file_path)\n                    except Exception as e:\n                        print(json.dumps({\"ok\": False, \"error\": f\"Docling conversion error: {e}\", \"meta\": meta}))\n                        return\n\n                    ok = False\n                    if hasattr(res, \"status\"):\n                        try:\n                            ok = (res.status == ConversionStatus.SUCCESS) or (str(res.status).lower() == \"success\")\n                        except Exception:\n                            ok = (str(res.status).lower() == \"success\")\n                    if not ok and hasattr(res, \"document\"):\n                        ok = getattr(res, \"document\", None) is not None\n                    if not ok:\n                        print(json.dumps({\"ok\": False, \"error\": \"Docling conversion failed\", \"meta\": meta}))\n                        return\n\n                    doc = getattr(res, \"document\", None)\n                    if doc is None:\n                        print(json.dumps({\"ok\": False, \"error\": \"Docling produced no document\", \"meta\": meta}))\n                        return\n\n                    if markdown:\n                        text = export_markdown(doc, ImageRefMode, image_mode, img_ph, pg_ph)\n                        print(json.dumps({\"ok\": True, \"mode\": \"markdown\", \"text\": text, \"meta\": meta}))\n                        return\n\n                    # structured\n                    try:\n                        doc_dict = doc.export_to_dict()\n                    except Exception as e:\n                        print(json.dumps({\"ok\": False, \"error\": f\"Docling export_to_dict failed: {e}\", \"meta\": meta}))\n                        return\n\n                    rows = to_rows(doc_dict)\n                    print(json.dumps({\"ok\": True, \"mode\": \"structured\", \"doc\": rows, \"meta\": meta}))\n                except Exception as e:\n                    print(\n                        json.dumps({\n                            \"ok\": False,\n                            \"error\": f\"Docling processing error: {e}\",\n                            \"meta\": {\"file_path\": file_path},\n                        })\n                    )\n\n            if __name__ == \"__main__\":\n                main()\n            \"\"\"\n        )\n\n        # Validate file_path to avoid command injection or unsafe input\n        if not isinstance(args[\"file_path\"], str) or any(c in args[\"file_path\"] for c in [\";\", \"|\", \"&\", \"$\", \"`\"]):\n            return Data(data={\"error\": \"Unsafe file path detected.\", \"file_path\": args[\"file_path\"]})\n\n        proc = subprocess.run(  # noqa: S603\n            [sys.executable, \"-u\", \"-c\", child_script],\n            input=json.dumps(args).encode(\"utf-8\"),\n            capture_output=True,\n            check=False,\n        )\n\n        if not proc.stdout:\n            err_msg = proc.stderr.decode(\"utf-8\", errors=\"replace\") or \"no output from child process\"\n            return Data(data={\"error\": f\"Docling subprocess error: {err_msg}\", \"file_path\": file_path})\n\n        try:\n            result = json.loads(proc.stdout.decode(\"utf-8\"))\n        except Exception as e:  # noqa: BLE001\n            err_msg = proc.stderr.decode(\"utf-8\", errors=\"replace\")\n            return Data(\n                data={\"error\": f\"Invalid JSON from Docling subprocess: {e}. stderr={err_msg}\", \"file_path\": file_path},\n            )\n\n        if not result.get(\"ok\"):\n            return Data(data={\"error\": result.get(\"error\", \"Unknown Docling error\"), **result.get(\"meta\", {})})\n\n        meta = result.get(\"meta\", {})\n        if result.get(\"mode\") == \"markdown\":\n            exported_content = str(result.get(\"text\", \"\"))\n            return Data(\n                text=exported_content,\n                data={\"exported_content\": exported_content, \"export_format\": self.EXPORT_FORMAT, **meta},\n            )\n\n        rows = list(result.get(\"doc\", []))\n        return Data(data={\"doc\": rows, \"export_format\": self.EXPORT_FORMAT, **meta})\n\n    def process_files(\n        self,\n        file_list: list[BaseFileComponent.BaseFile],\n    ) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Process input files.\n\n        - Single file + advanced_mode => Docling in a separate process.\n        - Otherwise => standard parsing in current process (optionally threaded).\n        \"\"\"\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        def process_file_standard(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                self.log(f\"File not found: {file_path}. Error: {e}\")\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                self.log(f\"Unexpected error processing {file_path}: {e}\")\n                if not silent_errors:\n                    raise\n                return None\n\n        # Advanced path: only for a single Docling-compatible file\n        if len(file_list) == 1:\n            file_path = str(file_list[0].path)\n            if self.advanced_mode and self._is_docling_compatible(file_path):\n                advanced_data: Data | None = self._process_docling_in_subprocess(file_path)\n\n                # --- UNNEST: expand each element in `doc` to its own Data row\n                payload = getattr(advanced_data, \"data\", {}) or {}\n                doc_rows = payload.get(\"doc\")\n                if isinstance(doc_rows, list):\n                    rows: list[Data | None] = [\n                        Data(\n                            data={\n                                \"file_path\": file_path,\n                                **(item if isinstance(item, dict) else {\"value\": item}),\n                            },\n                        )\n                        for item in doc_rows\n                    ]\n                    return self.rollup_data(file_list, rows)\n\n                # If not structured, keep as-is (e.g., markdown export or error dict)\n                return self.rollup_data(file_list, [advanced_data])\n\n        # Standard multi-file (or single non-advanced) path\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_paths = [str(f.path) for f in file_list]\n        self.log(f\"Starting parallel processing of {len(file_paths)} files with concurrency: {concurrency}.\")\n        my_data = parallel_load_data(\n            file_paths,\n            silent_errors=self.silent_errors,\n            load_function=process_file_standard,\n            max_concurrency=concurrency,\n        )\n        return self.rollup_data(file_list, my_data)\n\n    # ------------------------------ Output helpers -----------------------------------\n\n    def load_files_helper(self) -> DataFrame:\n        result = self.load_files()\n\n        # Error condition - raise error if no text and an error is present\n        if not hasattr(result, \"text\"):\n            if hasattr(result, \"error\"):\n                raise ValueError(result.error[0])\n            msg = \"No content generated.\"\n            raise ValueError(msg)\n\n        return result\n\n    def load_files_dataframe(self) -> DataFrame:\n        \"\"\"Load files using advanced Docling processing and export to DataFrame format.\"\"\"\n        self.markdown = False\n        return self.load_files_helper()\n\n    def load_files_markdown(self) -> Message:\n        \"\"\"Load files using advanced Docling processing and export to Markdown format.\"\"\"\n        self.markdown = True\n        result = self.load_files_helper()\n        return Message(text=str(result.text[0]))\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "list": false,
                "list_add_label": "Add More",
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "list_add_label": "Add More",
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "doc_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Doc Key",
                "dynamic": false,
                "info": "The key to use for the DoclingDocument column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "doc_key",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "doc"
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "Server File Path",
                "dynamic": false,
                "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "markdown": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Markdown Export",
                "dynamic": false,
                "info": "Export processed documents to Markdown format. Only available when advanced mode is enabled.",
                "list": false,
                "list_add_label": "Add More",
                "name": "markdown",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "md_image_placeholder": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Image placeholder",
                "dynamic": false,
                "info": "Specify the image placeholder for markdown exports.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "md_image_placeholder",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "<!-- image -->"
              },
              "md_page_break_placeholder": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Page break placeholder",
                "dynamic": false,
                "info": "Add this placeholder between pages in the markdown output.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "md_page_break_placeholder",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "ocr_engine": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "OCR Engine",
                "dynamic": false,
                "external_options": {},
                "info": "OCR engine to use. Only available when pipeline is set to 'standard'.",
                "name": "ocr_engine",
                "options": [
                  "None",
                  "easyocr"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "easyocr"
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "adoc",
                  "asciidoc",
                  "asc",
                  "bmp",
                  "dotx",
                  "dotm",
                  "docm",
                  "jpeg",
                  "png",
                  "potx",
                  "ppsx",
                  "pptm",
                  "potm",
                  "ppsm",
                  "pptx",
                  "tiff",
                  "xls",
                  "xlsx",
                  "xhtml",
                  "webp",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "file_path": [
                  "8ad5e618-0cf0-4411-b646-7441d7110840/Primera_División_del_Perú.pdf"
                ],
                "info": "Supported file extensions: csv, json, pdf, txt, md, mdx, yaml, yml, xml, html, htm, docx, py, sh, sql, js, ts, tsx, adoc, asciidoc, asc, bmp, dotx, dotm, docm, jpeg, png, potx, ppsx, pptm, potm, ppsm, pptx, tiff, xls, xlsx, xhtml, webp; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "list": true,
                "list_add_label": "Add More",
                "name": "path",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "pipeline": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Pipeline",
                "dynamic": false,
                "external_options": {},
                "info": "Docling pipeline to use",
                "name": "pipeline",
                "options": [
                  "standard",
                  "vlm"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "standard"
              },
              "separator": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "Specify the separator to use between multiple outputs in Message format.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n\n"
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "list_add_label": "Add More",
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "[Deprecated] Use Multithreading",
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "message",
          "showNode": true,
          "type": "File"
        },
        "dragging": false,
        "id": "File-2MDv6",
        "measured": {
          "height": 259,
          "width": 320
        },
        "position": {
          "x": 716.2069390608563,
          "y": 413.58322239804005
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SplitText-hvWfL",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "https://docs.langflow.org/components-processing#split-text",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator",
              "text_key",
              "keep_separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "method": "split_text",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"
              },
              "data_inputs": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "external_options": {},
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SplitText"
        },
        "dragging": false,
        "id": "SplitText-hvWfL",
        "measured": {
          "height": 411,
          "width": 320
        },
        "position": {
          "x": 1203.546464719398,
          "y": 412.017308049191
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-52ttl",
          "node": {
            "description": "Para agragar páginas Web\n---\nEn el componente URL, agrega todas las URLs de las páginas web que quieras cargar a la Base de Conocimiento\n\nSi por agregar o eliminar URLs, se elimina la conexión con el Componente \"Split Text\", volver a enlazarlos arrastrando la salida hasta el punto \"Input\" del dicho componente.",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-52ttl",
        "measured": {
          "height": 324,
          "width": 347
        },
        "position": {
          "x": 325.538622222122,
          "y": -35.01051361818341
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 347
      },
      {
        "data": {
          "id": "note-Rg1G9",
          "node": {
            "description": "Para agregar documentos locales\n---\nEn el componente \"File\", agrega las rutas de todos tus documentos locales que quieras cargar a tu base de conocimiento, ten en cuenta que no se soportan todos los formatos de documentos.\n\nSi por agregar o eliminar documentos, se elimina la conexión con el Componente \"Split Text\", volver a enlazarlos arrastrando la salida hasta el punto \"Input\" del dicho componente.",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-Rg1G9",
        "measured": {
          "height": 324,
          "width": 343
        },
        "position": {
          "x": 326.80261794334115,
          "y": 423.81993318436224
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 343
      },
      {
        "data": {
          "id": "note-Ku5V9",
          "node": {
            "description": "IMPORTANTE:\n===\nAntes de ejecutar el flujo debe asegurarse lo siguiente:\n- Componente Qdrant debe estar configurado:\n  (Si la instancia es local, el contendor debe estar en ejecución y la URL debe ser \"http://localhost:6333\", si es desde la web de Qdrant, se debe ingresar la URL de tu cluster y su API Key)\n- Ollama debe estar ejecutando y haber descargado el modelo all-minilm (Si en el componente \"Ollama Embeddings\" no sale el modelo, elegirlo en la lista de modelos, solo funcionará si Ollama esta en ejecución)\n- Agregar las rutas de las paginas web a agregar a la Base de Conocimiento.\n- Agregar las rutas de los documentos locales a agregar a la Base de Conocimiento.\n\n**Para ejecutar el flujo solo dar clic en el botón \"Run componente\" del componente Qdrant** (triangulo en la esquina superior izquierda)",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-Ku5V9",
        "measured": {
          "height": 458,
          "width": 498
        },
        "position": {
          "x": 1971.6206996364758,
          "y": -396.3457477867009
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "note-0xXxf",
          "node": {
            "description": "\nSe puede usar un proveedor externo como Goggle u OpenAI pero necesitaras un API Key y probablemente necesites una cuenta de pago con saldo (Los límites de la cuenta gratuita de Gemini no son suficientes)",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "height": 324,
        "id": "note-0xXxf",
        "measured": {
          "height": 324,
          "width": 352
        },
        "position": {
          "x": 1683.83871613268,
          "y": 1059.3860673712456
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 352
      }
    ],
    "viewport": {
      "x": -64.4627091900611,
      "y": 311.4191372427666,
      "zoom": 0.7751068365914625
    }
  },
  "description": "Crear Base de Conocimiento del Futbol Peruano",
  "endpoint_name": null,
  "id": "10a66a80-2a59-43c0-a916-a9c87668662c",
  "is_component": false,
  "last_tested_version": "1.6.8",
  "name": "Crear BC Futbol Peruano",
  "tags": []
}